{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Manually specify the parent directory (replace with the actual path to your parent directory)\n",
    "parent_directory = '/home/abdulrauf/Desktop/augmix'\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Subset\n",
    "from multiprocessing import Pool\n",
    "from networks.resnet import ResNet_Model\n",
    "from utils import get_accuracy\n",
    "import torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_classes):\n",
    "    \"\"\"Creates a torchvision model (CNN or Transformer) and modifies the classification head.\"\"\"\n",
    "\n",
    "    model = models.__dict__['swin_v2_b']()\n",
    "\n",
    "    # Try to identify and replace the classification head\n",
    "    if hasattr(model, 'fc') and isinstance(model.fc, torch.nn.Linear):\n",
    "        # For models like ResNet\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.fc.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    elif hasattr(model, 'head') and isinstance(model.head, torch.nn.Linear):\n",
    "        # For transformer models like swin_v2_b, vit_b_16, etc.\n",
    "        model.head = torch.nn.Linear(model.head.in_features, num_classes)\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in model.head.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Model '{'swin_v2_b'}' does not have a recognizable classification head ('.fc' or '.head').\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, test_loader):\n",
    "  \"\"\"Evaluate network on given dataset.\"\"\"\n",
    "  net.eval()\n",
    "  total_loss = 0.\n",
    "  total_correct = 0\n",
    "  with torch.no_grad():\n",
    "    for images, targets in test_loader:\n",
    "      images, targets = images.cuda(), targets.cuda()\n",
    "      logits = net(images)\n",
    "      loss = F.cross_entropy(logits, targets)\n",
    "      pred = logits.data.max(1)[1]\n",
    "      total_loss += float(loss.data)\n",
    "      total_correct += pred.eq(targets.data).sum().item()\n",
    "\n",
    "  return total_loss / len(test_loader.dataset), total_correct / len(\n",
    "      test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_base = create_model(100)\n",
    "net_base = torch.nn.DataParallel(net_base).cuda()\n",
    "cudnn.benchmark = True\n",
    "checkpoint =  torch.load('/home/abdulrauf/Desktop/augmix/snapshots/IN100checkpoint.pth.tar')\n",
    "net_base.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_AX = create_model(100)\n",
    "net_AX = torch.nn.DataParallel(net_AX).cuda()\n",
    "cudnn.benchmark = True\n",
    "checkpoint =  torch.load('/home/abdulrauf/Desktop/augmix/snapshots/AXcheckpoint.pth.tar')\n",
    "net_AX.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_REVa = create_model(100)\n",
    "net_REVa = torch.nn.DataParallel(net_REVa).cuda()\n",
    "cudnn.benchmark = True\n",
    "checkpoint =  torch.load('/home/abdulrauf/Desktop/augmix/snapshots/REVacheckpoint_{args.model}.pth.tar')\n",
    "net_REVa.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from typing import Optional, Callable, Tuple\n",
    "\n",
    "# Assuming PREPROCESSINGS['Res256Crop224'] is a predefined transformation\n",
    "# If not, you can define it manually like below:\n",
    "PREPROCESSINGS = {\n",
    "    'Res256Crop224': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}\n",
    "\n",
    "def load_imagenet(\n",
    "    n_examples: Optional[int] = 500,\n",
    "    data_dir: str = './data',\n",
    "    transforms_test: Callable = PREPROCESSINGS['Res256Crop224']\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if n_examples > 5000:\n",
    "        raise ValueError(\n",
    "            'The evaluation is currently possible on at most 5000 points.')\n",
    "\n",
    "    # Use PyTorch's built-in ImageFolder\n",
    "    imagenet_dataset = datasets.ImageFolder(root=data_dir + '/val', transform=transforms_test)\n",
    "\n",
    "    # Create DataLoader for the test set\n",
    "    test_loader = DataLoader(imagenet_dataset, batch_size=n_examples, shuffle=False, num_workers=4)\n",
    "\n",
    "    # Get a batch of data\n",
    "    x_test, y_test = next(iter(test_loader))\n",
    "\n",
    "    return x_test, y_test\n",
    "\n",
    "def train_data_loader(\n",
    "    n_examples: Optional[int] = 5000,\n",
    "    data_dir: str = './data',\n",
    "    transforms_test: Callable = PREPROCESSINGS['Res256Crop224']\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if n_examples > 5000:\n",
    "        raise ValueError(\n",
    "            'The evaluation is currently possible on at most 5000 points.')\n",
    "\n",
    "    # Use PyTorch's built-in ImageFolder\n",
    "    imagenet_dataset = datasets.ImageFolder(root=data_dir + '/train', transform=transforms_test)\n",
    "\n",
    "    # Create DataLoader for the test set\n",
    "    test_loader = DataLoader(imagenet_dataset, batch_size=n_examples, shuffle=True, num_workers=4)\n",
    "\n",
    "\n",
    "    return test_loader\\\n",
    "    \n",
    "\n",
    "def test_data_loader(\n",
    "    n_examples: Optional[int] = 5000,\n",
    "    data_dir: str = './data',\n",
    "    transforms_test: Callable = PREPROCESSINGS['Res256Crop224']\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    if n_examples > 5000:\n",
    "        raise ValueError(\n",
    "            'The evaluation is currently possible on at most 5000 points.')\n",
    "\n",
    "    # Use PyTorch's built-in ImageFolder\n",
    "    imagenet_dataset = datasets.ImageFolder(root=data_dir + '/val', transform=transforms_test)\n",
    "\n",
    "    # Create DataLoader for the test set\n",
    "    test_loader = DataLoader(imagenet_dataset, batch_size=n_examples, shuffle=False, num_workers=4)\n",
    "\n",
    "\n",
    "    return test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = load_imagenet(n_examples=5000, data_dir= '/media/abdulrauf/c6e51537-17d9-4e8c-bfac-00f1c3719a0b/IN100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing the models performances on adversarial generation types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGD(model_name=DataParallel, device=cuda:0, attack_mode=default, targeted=False, normalization_used=True, eps=0.01568627450980392, alpha=0.0044444444444444444, steps=40, random_start=True)\n"
     ]
    }
   ],
   "source": [
    "atk = torchattacks.PGD(net_base, eps=4/255, alpha=1/225, steps=40, random_start=True)\n",
    "atk.set_normalization_used(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "print(atk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarial_dataset_in_batches(x_test, y_test, atk, batch_size=50):\n",
    "    # Initialize an empty list to store adversarial images\n",
    "    adv_images_list = []\n",
    "\n",
    "    # Get the number of samples in the test dataset\n",
    "    num_samples = x_test.size(0)\n",
    "    \n",
    "    # Process the dataset in batches\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        # Select the current batch of images and labels\n",
    "        x_batch = x_test[i:i + batch_size]\n",
    "        y_batch = y_test[i:i + batch_size]\n",
    "        \n",
    "        # Generate adversarial examples for the current batch\n",
    "        adv_batch = atk(x_batch, y_batch)\n",
    "        \n",
    "        # Append the generated adversarial examples to the list\n",
    "        adv_images_list.append(adv_batch)\n",
    "    \n",
    "    # Concatenate the list of adversarial examples into a single tensor\n",
    "    adv_images = torch.cat(adv_images_list, dim=0)\n",
    "\n",
    "    return adv_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_images = generate_adversarial_dataset_in_batches(x_test, y_test, atk, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = test_data_loader(n_examples=100, data_dir= '/media/abdulrauf/c6e51537-17d9-4e8c-bfac-00f1c3719a0b/IN100')\n",
    "# val_loader.data =  adv_images\n",
    "# val_loader.targets = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model Acc: 0.00 %\n",
      "AX model Acc: 49.20 %\n",
      "REVa model Acc: 75.30 %\n"
     ]
    }
   ],
   "source": [
    "acc1 = get_accuracy(net_base, [(adv_images.to(device), y_test.to(device))])\n",
    "acc2 = get_accuracy(net_AX, [(adv_images.to(device), y_test.to(device))])\n",
    "acc3 = get_accuracy(net_REVa, [(adv_images.to(device), y_test.to(device))])\n",
    "print('Base model Acc: %2.2f %%'%(acc1))\n",
    "print('AX model Acc: %2.2f %%'%(acc2))\n",
    "print('REVa model Acc: %2.2f %%'%(acc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FGSM adversarial performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FGSM(model_name=DataParallel, device=cuda:0, attack_mode=default, targeted=False, normalization_used=True, eps=0.01568627450980392)\n"
     ]
    }
   ],
   "source": [
    "atk1 = torchattacks.FGSM(net_base, eps=4/255)\n",
    "atk1.set_normalization_used(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "print(atk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_images_FGSM = generate_adversarial_dataset_in_batches(x_test, y_test, atk1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model Acc: 22.54 %\n",
      "AX model Acc: 50.86 %\n",
      "REVa model Acc: 66.96 %\n"
     ]
    }
   ],
   "source": [
    "acc1 = get_accuracy(net_base, [(adv_images_FGSM.to(device), y_test.to(device))])\n",
    "acc2 = get_accuracy(net_AX, [(adv_images_FGSM.to(device), y_test.to(device))])\n",
    "acc3 = get_accuracy(net_REVa, [(adv_images_FGSM.to(device), y_test.to(device))])\n",
    "print('Base model Acc: %2.2f %%'%(acc1))\n",
    "print('AX model Acc: %2.2f %%'%(acc2))\n",
    "print('REVa model Acc: %2.2f %%'%(acc3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation BIM methods attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIM(model_name=DataParallel, device=cuda:0, attack_mode=default, targeted=False, normalization_used=True, eps=0.01568627450980392, alpha=0.00392156862745098, steps=10)\n"
     ]
    }
   ],
   "source": [
    "atk2 = torchattacks.BIM(net_base, eps=4/255, alpha=1/255, steps=10)\n",
    "atk2.set_normalization_used(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "print(atk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_images_BIM = generate_adversarial_dataset_in_batches(x_test, y_test, atk2, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model Acc: 0.02 %\n",
      "AX model Acc: 37.72 %\n",
      "REVa model Acc: 72.50 %\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create dataset and dataloader\n",
    "adv_dataset = TensorDataset(adv_images_BIM, y_test)\n",
    "adv_loader = DataLoader(adv_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Get accuracy\n",
    "acc1 = get_accuracy(net_base, adv_loader, device=device)\n",
    "acc2 = get_accuracy(net_AX, adv_loader, device=device)\n",
    "acc3 = get_accuracy(net_REVa, adv_loader, device=device)\n",
    "\n",
    "print(f'Base model Acc: {acc1:.2f} %')\n",
    "print(f'AX model Acc: {acc2:.2f} %')\n",
    "print(f'REVa model Acc: {acc3:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of RFGSM attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFGSM(model_name=DataParallel, device=cuda:0, attack_mode=default, targeted=False, normalization_used=True, eps=0.01568627450980392, alpha=0.00392156862745098, steps=10)\n"
     ]
    }
   ],
   "source": [
    "atk3 = torchattacks.RFGSM(net_base, eps=4/255, alpha=1/255, steps=10)\n",
    "atk3.set_normalization_used(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "print(atk3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_images_RFGSM = generate_adversarial_dataset_in_batches(x_test, y_test, atk3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model Acc: 0.02 %\n",
      "AX model Acc: 39.36 %\n",
      "REVa model Acc: 72.50 %\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create dataset and dataloader\n",
    "adv_dataset = TensorDataset(adv_images_RFGSM, y_test)\n",
    "adv_loader = DataLoader(adv_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Get accuracy\n",
    "acc1 = get_accuracy(net_base, adv_loader, device=device)\n",
    "acc2 = get_accuracy(net_AX, adv_loader, device=device)\n",
    "acc3 = get_accuracy(net_REVa, adv_loader, device=device)\n",
    "\n",
    "print(f'Base model Acc: {acc1:.2f} %')\n",
    "print(f'AX model Acc: {acc2:.2f} %')\n",
    "print(f'REVa model Acc: {acc3:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of UMIFGSM attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIFGSM(model_name=DataParallel, device=cuda:0, attack_mode=default, targeted=False, normalization_used=True, eps=0.01568627450980392, steps=10, decay=1.0, alpha=0.00392156862745098)\n"
     ]
    }
   ],
   "source": [
    "atk4 = torchattacks.MIFGSM(net_base, eps=4/255, alpha=1/255, steps=10)\n",
    "atk4.set_normalization_used(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "print(atk4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_images_MIFGSM = generate_adversarial_dataset_in_batches(x_test, y_test, atk4, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model Acc: 0.16 %\n",
      "AX model Acc: 25.84 %\n",
      "REVa model Acc: 65.30 %\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create dataset and dataloader\n",
    "adv_dataset = TensorDataset(adv_images_MIFGSM, y_test)\n",
    "adv_loader = DataLoader(adv_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Get accuracy\n",
    "acc1 = get_accuracy(net_base, adv_loader, device=device)\n",
    "acc2 = get_accuracy(net_AX, adv_loader, device=device)\n",
    "acc3 = get_accuracy(net_REVa, adv_loader, device=device)\n",
    "\n",
    "print(f'Base model Acc: {acc1:.2f} %')\n",
    "print(f'AX model Acc: {acc2:.2f} %')\n",
    "print(f'REVa model Acc: {acc3:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "class UAPAttack:\n",
    "    def __init__(self, model, data_loader, epsilon=0.1, alpha=0.01, max_iter=100, device='cuda'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - model: The target model.\n",
    "        - data_loader: The dataset (DataLoader) for which we will generate the UAP.\n",
    "        - epsilon: Perturbation step size.\n",
    "        - alpha: Learning rate for the perturbation update.\n",
    "        - max_iter: Maximum iterations for optimization.\n",
    "        - device: Device to run the computation ('cpu' or 'cuda').\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.data_loader = data_loader\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.device = device\n",
    "\n",
    "        # Initialize perturbation (delta) with small random values instead of zeros\n",
    "        # This helps avoid starting with a black background (zeros).\n",
    "        self.delta = torch.randn_like(next(iter(self.data_loader))[0][0]).to(self.device) * 0.001\n",
    "        self.delta.requires_grad = True  # Allow gradients to be computed for delta\n",
    "\n",
    "    def generate_uap(self):\n",
    "        # Optimizer for perturbation\n",
    "        optimizer = optim.Adam([self.delta], lr=self.alpha)\n",
    "\n",
    "        for iteration in range(self.max_iter):\n",
    "            total_loss = 0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, targets in self.data_loader:\n",
    "                inputs, targets = inputs.to(self.device), targets.to(self.device)\n",
    "\n",
    "                # Apply the perturbation to the inputs\n",
    "                perturbed_inputs = inputs + self.delta\n",
    "                perturbed_inputs = torch.clamp(perturbed_inputs, 0, 1)  # Clamp the values to be in [0, 1]\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = self.model(perturbed_inputs)\n",
    "                loss = torch.nn.CrossEntropyLoss()(outputs, targets)  # Standard cross-entropy loss\n",
    "\n",
    "                # Backward pass to compute gradients of delta\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Evaluate the effectiveness of the attack (whether the model misclassifies)\n",
    "                _, predicted = outputs.max(1)\n",
    "                correct += (predicted != targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "            # Print the current status of the attack\n",
    "            print(f\"Iteration {iteration+1}/{self.max_iter}, Loss: {loss.item()}, Misclassification rate: {100 * correct / total}%\")\n",
    "\n",
    "            # Check if perturbation exceeds epsilon (clipping)\n",
    "            self.delta.data = torch.clamp(self.delta.data, -self.epsilon, self.epsilon)\n",
    "\n",
    "        return self.delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1/10, Loss: 2.4559857845306396, Misclassification rate: 40.04%\n",
      "Iteration 2/10, Loss: 1.6305601596832275, Misclassification rate: 30.08%\n",
      "Iteration 3/10, Loss: 1.3283511400222778, Misclassification rate: 26.32%\n",
      "Iteration 4/10, Loss: 1.163020133972168, Misclassification rate: 24.38%\n",
      "Iteration 5/10, Loss: 1.08456552028656, Misclassification rate: 23.4%\n",
      "Iteration 6/10, Loss: 1.0209968090057373, Misclassification rate: 22.76%\n",
      "Iteration 7/10, Loss: 0.9823630452156067, Misclassification rate: 22.24%\n",
      "Iteration 8/10, Loss: 0.9558146595954895, Misclassification rate: 22.04%\n",
      "Iteration 9/10, Loss: 0.9502792358398438, Misclassification rate: 21.96%\n",
      "Iteration 10/10, Loss: 0.9213523864746094, Misclassification rate: 21.8%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate UAP attack\n",
    "uap_attack = UAPAttack(net_base, val_loader, epsilon=0.1, alpha=0.01, max_iter=10, device='cuda')\n",
    "\n",
    "# Generate the UAP perturbation\n",
    "uap = uap_attack.generate_uap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming UAPAttack class is already defined\n",
    "\n",
    "def generate_adversarial_dataset_in_batches_uap(x_test, y_test, uap, batch_size=50):\n",
    "    \"\"\"\n",
    "    Generate an adversarial dataset using a universal adversarial perturbation (UAP).\n",
    "\n",
    "    Parameters:\n",
    "    - x_test: Input test data (images).\n",
    "    - y_test: Corresponding labels for the test data.\n",
    "    - atk: The UAPAttack object used for generating the universal perturbation.\n",
    "    - batch_size: The size of the batch to process at a time.\n",
    "\n",
    "    Returns:\n",
    "    - adv_images: A tensor containing the adversarial images generated by applying the UAP.\n",
    "    \"\"\"\n",
    "    # Initialize an empty list to store adversarial images\n",
    "    adv_images_list = []\n",
    "\n",
    "    # Get the number of samples in the test dataset\n",
    "    num_samples = x_test.size(0)\n",
    "    \n",
    "    # Generate the UAP perturbation (only need to generate once)\n",
    "    \n",
    "    # Process the dataset in batches\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        # Select the current batch of images and labels\n",
    "        x_batch = x_test[i:i + batch_size]\n",
    "        y_batch = y_test[i:i + batch_size]\n",
    "        \n",
    "        # Apply the universal perturbation (UAP) to the batch\n",
    "        adv_batch = x_batch + uap.cpu().detach()\n",
    "        adv_batch = torch.clamp(adv_batch, 0, 1)  # Ensure the pixel values remain in the valid range [0, 1]\n",
    "        \n",
    "        # Append the generated adversarial examples to the list\n",
    "        adv_images_list.append(adv_batch)\n",
    "    \n",
    "    # Concatenate the list of adversarial examples into a single tensor\n",
    "    adv_images = torch.cat(adv_images_list, dim=0)\n",
    "\n",
    "    return adv_images\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a pretrained model and a data loader `x_test` and `y_test` as your test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate adversarial dataset using the UAP\n",
    "adv_images_uap = generate_adversarial_dataset_in_batches_uap(x_test, y_test, uap, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model Acc: 78.54 %\n",
      "AX model Acc: 64.04 %\n",
      "REVa model Acc: 49.60 %\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create dataset and dataloader\n",
    "adv_dataset = TensorDataset(adv_images_uap, y_test)\n",
    "adv_loader = DataLoader(adv_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Get accuracy\n",
    "acc1 = get_accuracy(net_base, adv_loader, device=device)\n",
    "acc2 = get_accuracy(net_AX, adv_loader, device=device)\n",
    "acc3 = get_accuracy(net_REVa, adv_loader, device=device)\n",
    "\n",
    "print(f'Base model Acc: {acc1:.2f} %')\n",
    "print(f'AX model Acc: {acc2:.2f} %')\n",
    "print(f'REVa model Acc: {acc3:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are the corruption error [[100.    77.46  99.98  99.96  99.84  21.84]\n",
      " [ 51.18  49.14  62.28  60.44  74.16  36.42]\n",
      " [ 24.7   33.04  27.5   27.5   34.7   50.4 ]]\n",
      "[83.18      55.6033333 32.9733333]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Given data\n",
    "corruption_types = [\n",
    "    [0.00, 22.54, 0.02, 0.04, 0.16, 78.16],   \n",
    "    [48.82, 50.86, 37.72, 39.56, 25.84, 63.58], \n",
    "    [75.30, 66.96, 72.50, 72.5, 65.30,49.60 ]\n",
    "] \n",
    "\n",
    "\n",
    "# Convert the data to a NumPy array for easier calculations\n",
    "corruption_array = np.array(corruption_types)\n",
    "\n",
    "#print the corruption errors\n",
    "print(f\"these are the corruption error {100-corruption_array}\")\n",
    "\n",
    "# Compute the average for each corruption type\n",
    "averages = corruption_array.mean(axis=1)\n",
    "\n",
    "# Compute 1 - averages and round to 6 decimal places\n",
    "result = np.round(100 - averages, 7)\n",
    "\n",
    "# Print the result\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "augmix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
